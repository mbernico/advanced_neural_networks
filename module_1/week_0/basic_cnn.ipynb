{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1.  Download this dataset:  https://www.kaggle.com/slothkong/10-monkey-species  \n",
    "        You may need to create a kaggle account / sign in to accomplish this.\n",
    "        \n",
    "2. Git clone this repo or download this notebook.\n",
    "3. Create a new folder, data in the same directory this notebook is located\n",
    "4. Unzip the monkey dataset in this folder.  Then unzip the train.zip and validation.zip folders.\n",
    "5. The directory hierarchy should be ../data/10-monkey-species/training and ../data/10-monkey-species/validation.  Each of these subdirectories should contain a directory per label, n0 thru n9.\n",
    "\n",
    "6. Implement the code in build_model()\n",
    "\n",
    "** You will most certainly need access to a GPU for this assignment **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "In addition to implementing build_model(), answer these questions.\n",
    "\n",
    "1.  Is this network a high bias or high variance model?  Refer to chapter 1 and look at this model in tensorboard if you're unsure.\n",
    "\n",
    "2. What is the likely cause of the issue you identified in the previous question?\n",
    "\n",
    "3.  What might you do to make this network perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these seeds are both required for reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    def __init__(self):\n",
    "        self.feature_extraction_epochs = 10\n",
    "        self.fine_tuning_epochs = 20\n",
    "        self.epochs_without_transfer_learning = 100\n",
    "        self.batch_size = 30\n",
    "        self.data_dir = \"data/10-monkey-species/training\"\n",
    "        self.val_dir = \"data/10-monkey-species/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = Input(shape=(299,299,3), name=\"input\")\n",
    "    \n",
    "    \"\"\"YOUR CODE HERE\n",
    "    Network Architecture should be\n",
    "   \n",
    "    Conv2D 128 units, 3x3 kernel, relu activation\n",
    "    MaxPooling2D 2x2 pool size\n",
    "    \n",
    "    Conv2D 64 units, 3x3 kernel, relu activation\n",
    "    MaxPooling2D 2x2 pool size\n",
    "    \n",
    "    Conv2D 32 units, 3x3 kernel, relu activation\n",
    "    MaxPooling2D 2x2 pool size\n",
    "    \n",
    "    Conv2D 16 units, 3x3 kernel, relu activation\n",
    "    MaxPooling2D 2x2 pool size\n",
    "    \n",
    "    Dense 1024\n",
    "    Dense softmax layer (named \"output\")\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # finalize and compile\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_callbacks(name):\n",
    "    tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"tensorboard_log\", name), write_graph=True, write_grads=False)\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=\"./model-weights-\" + name + \".{epoch:02d}-{val_loss:.6f}.hdf5\", monitor='val_loss',\n",
    "                                          verbose=0, save_best_only=True)\n",
    "    return [tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_data(train_data_dir, val_data_dir, img_width=299, img_height=299, batch_size=16):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        val_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, train_generator, val_generator, batch_size, epochs, name):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.n // batch_size,\n",
    "        callbacks=create_callbacks(name=name),\n",
    "        verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, val_generator, batch_size):\n",
    "    scores = model.evaluate_generator(val_generator, steps=val_generator.n // batch_size)\n",
    "    print(\"Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configuration class\n",
    "This has all our model configuration parameters in it.  It's defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "If everything is setup correctly, this method will print  \n",
    "\"  \n",
    "Found 1097 images belonging to 10 classes.  \n",
    "Found 272 images belonging to 10 classes.  \n",
    "\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, val_generator = setup_data(config.data_dir, config.val_dir, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile your model and print a summary\n",
    "\n",
    "Your network should look like this.\n",
    "\n",
    "\n",
    "input (InputLayer)           (None, 299, 299, 3)       0         \n",
    "_________________________________________________________________\n",
    "conv_1 (Conv2D)              (None, 297, 297, 128)     3584      \n",
    "_________________________________________________________________\n",
    "pool_1 (MaxPooling2D)        (None, 148, 148, 128)     0         \n",
    "_________________________________________________________________\n",
    "conv_2 (Conv2D)              (None, 146, 146, 64)      73792     \n",
    "_________________________________________________________________\n",
    "pool_2 (MaxPooling2D)        (None, 73, 73, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv_3 (Conv2D)              (None, 71, 71, 32)        18464     \n",
    "_________________________________________________________________\n",
    "pool_3 (MaxPooling2D)        (None, 35, 35, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv_4 (Conv2D)              (None, 33, 33, 16)        4624      \n",
    "_________________________________________________________________\n",
    "pool_4 (MaxPooling2D)        (None, 16, 16, 16)        0         \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 4096)              0         \n",
    "_________________________________________________________________\n",
    "fc1 (Dense)                  (None, 1024)              4195328   \n",
    "_________________________________________________________________\n",
    "softmax (Dense)              (None, 10)                10250     \n",
    "\n",
    "Total params: 4,306,042\n",
    "Trainable params: 4,306,042\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "You're most certainly going to want a GPU to train this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_model(model, train_generator, val_generator,\n",
    "                  batch_size=config.batch_size,\n",
    "                  epochs=config.epochs_without_transfer_learning,\n",
    "                  name=\"without_transfer_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate your model.\n",
    "eval_model(model, val_generator, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save your model weights\n",
    "model.save(\"no_transfer_learning_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
