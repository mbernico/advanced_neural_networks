{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1.  Download this dataset:  https://www.kaggle.com/slothkong/10-monkey-species  \n",
    "        You may need to create a kaggle account / sign in to accomplish this.\n",
    "        \n",
    "2. Git clone this repo or download this notebook.\n",
    "3. Create a new folder, data in the same directory this notebook is located\n",
    "4. Unzip the monkey dataset in this folder.  Then unzip the train.zip and validation.zip folders.\n",
    "5. The directory hierarchy should be ../data/10-monkey-species/training and ../data/10-monkey-species/validation.  Each of these subdirectories should contain a directory per label, n0 thru n9.\n",
    "\n",
    "6. Implement the code in build_model()\n",
    "\n",
    "** You will most certainly need access to a GPU for this assignment **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "In addition to implementing build_model(), answer these questions.\n",
    "\n",
    "1.  Is this network a high bias or high variance model?  Refer to chapter 1 and look at this model in tensorboard if you're unsure.\n",
    "\n",
    "2. What is the likely cause of the issue you identified in the previous question?\n",
    "\n",
    "3.  What might you do to make this network perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these seeds are both required for reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    def __init__(self):\n",
    "        self.feature_extraction_epochs = 10\n",
    "        self.fine_tuning_epochs = 20\n",
    "        self.epochs_without_transfer_learning = 100\n",
    "        self.batch_size = 30\n",
    "        self.data_dir = \"data/10-monkey-species/training\"\n",
    "        self.val_dir = \"data/10-monkey-species/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_feature_extraction():\n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # make sure we're back at a 2d tensor\n",
    "    x = Dense(1024, activation='relu')(x)  # add one fully connected layer\n",
    "    predictions = Dense(10, activation='softmax')(x)  # 10 monkey, therefore 10 output units w softmax activation\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # make the base model untrainable (frozen)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_fine_tuning(model, learning_rate=0.0001, momentum=0.9):\n",
    "\n",
    "        for layer in model.layers[:249]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[249:]:\n",
    "            layer.trainable = True\n",
    "        model.compile(optimizer=SGD(lr=learning_rate, momentum=momentum), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_callbacks(name):\n",
    "    tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"tensorboard_log\", name), write_graph=True, write_grads=False)\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=\"./model-weights-\" + name + \".{epoch:02d}-{val_loss:.6f}.hdf5\", monitor='val_loss',\n",
    "                                          verbose=0, save_best_only=True)\n",
    "    return [tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_data(train_data_dir, val_data_dir, img_width=299, img_height=299, batch_size=16):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        val_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, train_generator, val_generator, batch_size, epochs, name):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.n // batch_size,\n",
    "        callbacks=create_callbacks(name=name),\n",
    "        verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, val_generator, batch_size):\n",
    "    scores = model.evaluate_generator(val_generator, steps=val_generator.n // batch_size)\n",
    "    print(\"Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configuration class\n",
    "This has all our model configuration parameters in it.  It's defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "If everything is setup correctly, this method will print  \n",
    "\"  \n",
    "Found 1097 images belonging to 10 classes.  \n",
    "Found 272 images belonging to 10 classes.  \n",
    "\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, val_generator = setup_data(config.data_dir, config.val_dir, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Model Training\n",
    "\n",
    "Here we will train the feature extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model_feature_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework Q1: How many trainable parameters does this model have? How many more parameters exist in this model than the model we built last week?\n",
    "    \n",
    "Homework Q2: How can we possibly train a network of this size on a small dataset without overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_model(model, train_generator, val_generator,\n",
    "                  batch_size=config.batch_size,\n",
    "                  epochs=config.feature_extraction_epochs,\n",
    "                  name=\"feature_extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model, val_generator, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning \n",
    "\n",
    "Here we will fine tune that same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_fine_tuning(model)\n",
    "model = fit_model(model, train_generator, val_generator,\n",
    "                      batch_size=config.batch_size,\n",
    "                      epochs=config.fine_tuning_epochs,\n",
    "                      name=\"fine_tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework Q3: Did fine tuning help significantly?\n",
    "    \n",
    "Homework Q4: Imagine we wanted to use the InceptionV3 model to create a classifier for detecting skin cancer.  You have 200 images of both cancerous and benign abnormal skin cells.  Do you expect Fine Tuning to be useful in solving this problem, or will feature selection be sufficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_model(model, val_generator, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Saving Model...\")\n",
    "model.save(\"transfer_learning_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
